{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc2d470",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "import seaborn as sns\n",
    "import plotly\n",
    "import plotly.graph_objs as go\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from plotly.offline import iplot, init_notebook_mode\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.initializers import glorot_uniform\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from IPython.display import display\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint, LearningRateScheduler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6b249c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jupyterthemes import jtplot\n",
    "jtplot.style(theme='monokai', context='notebook', ticks=True, grid=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654326d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir('./train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213a8f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(os.path.join('train','Mild'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae612836",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the number of images in the dataset\n",
    "train = []\n",
    "label = []\n",
    "\n",
    "# os.listdir returns the list of files in the folder, in this case image class names\n",
    "for i in os.listdir('./train'):\n",
    "    train_class = os.listdir(os.path.join('train',i))\n",
    "    for j in train_class:\n",
    "        img = os.path.join('train',i,j)\n",
    "        train.append(img)\n",
    "        label.append(i)\n",
    "print('Number of train images = {}'.format(len(train)))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f40691c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbb052e",
   "metadata": {},
   "outputs": [],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bce043",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(label);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be1bfb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(5, 5, figsize = (20, 20))\n",
    "count = 0\n",
    "for i in os.listdir('./train'):\n",
    "  # get the list of images in a given class\n",
    "  train_class = os.listdir(os.path.join('train', i))\n",
    "  # plot 5 images per class\n",
    "  for j in range(5):\n",
    "    img = os.path.join('train', i, train_class[j])\n",
    "    img = PIL.Image.open(img)\n",
    "    axs[count][j].title.set_text(i)\n",
    "    axs[count][j].imshow(img)  \n",
    "  count += 1\n",
    "\n",
    "fig.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed6fc65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the number of images in each class in the training dataset\n",
    "\n",
    "No_images_per_class = []\n",
    "Class_name = []\n",
    "for i in os.listdir('./train'):\n",
    "  train_class = os.listdir(os.path.join('train', i))\n",
    "  No_images_per_class.append(len(train_class))\n",
    "  Class_name.append(i)\n",
    "  print('Number of images in {} = {} \\n'.format(i, len(train_class)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfcea14",
   "metadata": {},
   "outputs": [],
   "source": [
    "retina_df = pd.DataFrame({'Image': train,'Labels': label})\n",
    "retina_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb379bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create run-time augmentation on training and test dataset\n",
    "# For training datagenerator, we add normalization, shear angle, zooming range and horizontal flip\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale = 1./255,\n",
    "        shear_range = 0.2,\n",
    "        validation_split = 0.15)\n",
    "\n",
    "# For test datagenerator, we only normalize the data.\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e026f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating datagenerator for training, validation and test dataset.\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    train,\n",
    "    directory='./',\n",
    "    x_col=\"Image\",\n",
    "    y_col=\"Labels\",\n",
    "    target_size=(256, 256),\n",
    "    color_mode=\"rgb\",\n",
    "    class_mode=\"categorical\",\n",
    "    batch_size=32,\n",
    "    subset='training')\n",
    "\n",
    "validation_generator = train_datagen.flow_from_dataframe(\n",
    "    train,\n",
    "    directory='./',\n",
    "    x_col=\"Image\",\n",
    "    y_col=\"Labels\",\n",
    "    target_size=(256, 256),\n",
    "    color_mode=\"rgb\",\n",
    "    class_mode=\"categorical\",\n",
    "    batch_size=32,\n",
    "    subset='training')\n",
    "\n",
    "validation_generator = train_datagen.flow_from_dataframe(\n",
    "    train,\n",
    "    directory='./',\n",
    "    x_col=\"Image\",\n",
    "    y_col=\"Labels\",\n",
    "    target_size=(256, 256),\n",
    "    color_mode=\"rgb\",\n",
    "    class_mode=\"categorical\",\n",
    "    batch_size=32,\n",
    "    subset='validation')\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    test,\n",
    "    directory='./',\n",
    "    x_col=\"Image\",\n",
    "    y_col=\"Labels\",\n",
    "    target_size=(256, 256),\n",
    "    color_mode=\"rgb\",\n",
    "    class_mode=\"categorical\",\n",
    "    batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe92388",
   "metadata": {},
   "outputs": [],
   "source": [
    "def res_block(X, filter, stage):\n",
    "  \n",
    "  # Convolutional_block\n",
    "  X_copy = X\n",
    "\n",
    "  f1 , f2, f3 = filter\n",
    "    \n",
    "  # Main Path\n",
    "  X = Conv2D(f1, (1,1),strides = (1,1), name ='res_'+str(stage)+'_conv_a', kernel_initializer= glorot_uniform(seed = 0))(X)\n",
    "  X = MaxPool2D((2,2))(X)\n",
    "  X = BatchNormalization(axis =3, name = 'bn_'+str(stage)+'_conv_a')(X)\n",
    "  X = Activation('relu')(X) \n",
    "\n",
    "  X = Conv2D(f2, kernel_size = (3,3), strides =(1,1), padding = 'same', name ='res_'+str(stage)+'_conv_b', kernel_initializer= glorot_uniform(seed = 0))(X)\n",
    "  X = BatchNormalization(axis =3, name = 'bn_'+str(stage)+'_conv_b')(X)\n",
    "  X = Activation('relu')(X) \n",
    "\n",
    "  X = Conv2D(f3, kernel_size = (1,1), strides =(1,1),name ='res_'+str(stage)+'_conv_c', kernel_initializer= glorot_uniform(seed = 0))(X)\n",
    "  X = BatchNormalization(axis =3, name = 'bn_'+str(stage)+'_conv_c')(X)\n",
    "\n",
    "\n",
    "  # Short path\n",
    "  X_copy = Conv2D(f3, kernel_size = (1,1), strides =(1,1),name ='res_'+str(stage)+'_conv_copy', kernel_initializer= glorot_uniform(seed = 0))(X_copy)\n",
    "  X_copy = MaxPool2D((2,2))(X_copy)\n",
    "  X_copy = BatchNormalization(axis =3, name = 'bn_'+str(stage)+'_conv_copy')(X_copy)\n",
    "\n",
    "  # ADD\n",
    "  X = Add()([X,X_copy])\n",
    "  X = Activation('relu')(X)\n",
    "\n",
    "  # Identity Block 1\n",
    "  X_copy = X\n",
    "\n",
    "\n",
    "  # Main Path\n",
    "  X = Conv2D(f1, (1,1),strides = (1,1), name ='res_'+str(stage)+'_identity_1_a', kernel_initializer= glorot_uniform(seed = 0))(X)\n",
    "  X = BatchNormalization(axis =3, name = 'bn_'+str(stage)+'_identity_1_a')(X)\n",
    "  X = Activation('relu')(X) \n",
    "= (3,3), strides =(1,1), padding = 'same', name ='res_'+str(stage)+'_identity_1_b', kernel_initializer= glorot_uniform(seed = 0))(X)\n",
    "  X = BatchNormalization(axis =3, name = 'bn_'+str(stage)+'_identity_1_b')(X)\n",
    "  X = Activation('relu')(X) \n",
    "\n",
    "  X = Conv2D(f3, kernel_size = (3,3), strides =(1,1), padding = 'same', name ='res_'+str(stage)+'_identity_1_b', kernel_initializer= glorot_uniform(seed = 0))(X)\n",
    "  X = BatchNormalization(axis =3, name = 'bn_'+str(stage)+'_identity_1_b')(X)\n",
    "  X = Activation('relu')(X)\n",
    "    X = Conv2D(f3, kernel_size = (1,1), strides =(1,1),name ='res_'+str(stage)+'_identity_1_c', kernel_initializer= glorot_uniform(seed = 0))(X)\n",
    "  X = BatchNormalization(axis =3, name = 'bn_'+str(stage)+'_identity_1_c')(X)\n",
    "\n",
    "  # ADD\n",
    "  X = Add()([X,X_copy])\n",
    "    \n",
    "  X = Activation('relu')(X)\n",
    "\n",
    "  # Identity Block 2\n",
    "  X_copy = X\n",
    "\n",
    "\n",
    "  # Main Path\n",
    "  X = Conv2D(f1, (1,1),strides = (1,1), name ='res_'+str(stage)+'_identity_2_a', kernel_initializer= glorot_uniform(seed = 0))(X)\n",
    "  X = BatchNormalization(axis =3, name = 'bn_'+str(stage)+'_identity_2_a')(X)\n",
    "  X = Activation('relu')(X) \n",
    "\n",
    "  X = Conv2D(f2, kernel_size = (3,3), strides =(1,1), padding = 'same', name ='res_'+str(stage)+'_identity_2_b', kernel_initializer= glorot_uniform(seed = 0))(X)\n",
    "  X = BatchNormalization(axis =3, name = 'bn_'+str(stage)+'_identity_2_b')(X)\n",
    "  X = Activation('relu')(X) \n",
    "\n",
    "  X = Conv2D(f3, kernel_size = (1,1), strides =(1,1),name ='res_'+str(stage)+'_identity_2_c', kernel_initializer= glorot_uniform(seed = 0))(X)\n",
    "  X = BatchNormalization(axis =3, name = 'bn_'+str(stage)+'_identity_2_c')(X)\n",
    "  \n",
    "    # ADD\n",
    "  X = Add()([X,X_copy])\n",
    "  X = Activation('relu')(X)\n",
    "    \n",
    "  return x  \n",
    "\n",
    "  \n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49ed70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (256,256,3)\n",
    "\n",
    "#Input tensor shape\n",
    "X_input = Input(input_shape)\n",
    "\n",
    "#Zero-padding\n",
    "\n",
    "X = ZeroPadding2D((3,3))(X_input)\n",
    "\n",
    "# 1 - stage\n",
    "\n",
    "X = Conv2D(64, (7,7), strides= (2,2), name = 'conv1', kernel_initializer= glorot_uniform(seed = 0))(X)\n",
    "X = BatchNormalization(axis =3, name = 'bn_conv1')(X)\n",
    "X = Activation('relu')(X)\n",
    "X = MaxPooling2D((3,3), strides= (2,2))(X)\n",
    "\n",
    "# 2- stage\n",
    "\n",
    "X = res_block(X, filter= [64,64,256], stage= 2)\n",
    "\n",
    "# 3- stage\n",
    "\n",
    "X = res_block(X, filter= [128,128,512], stage= 3)\n",
    "\n",
    "# 4- stage\n",
    "\n",
    "X = res_block(X, filter= [256,256,1024], stage= 4)\n",
    "\n",
    "# # 5- stage\n",
    "\n",
    "# X = res_block(X, filter= [512,512,2048], stage= 5)\n",
    "\n",
    "# Average Pooling\n",
    "\n",
    "X = AveragePooling2D((2,2), name = 'Averagea_Pooling')(X)\n",
    "\n",
    "# Final layer\n",
    "\n",
    "X = Flatten()(X)\n",
    "X = Dense(5, activation = 'softmax', name = 'Dense_final', kernel_initializer= glorot_uniform(seed=0))(X)\n",
    "model = Model( inputs= X_input, outputs = X, name = 'Resnet18')\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2cbf72",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics= ['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc70e7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using early stopping to exit training if validation loss is not decreasing even after certain epochs (patience)\n",
    "earlystopping = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=15)\n",
    "\n",
    "#save the best model with lower validation loss\n",
    "checkpointer = ModelCheckpoint(filepath=\"weights.hdf5\", verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a82698",
   "metadata": {},
   "outputs": [],
   "source": [
    "istory = model.fit(train_generator, steps_per_epoch = train_generator.n // 32, epochs = 2, validation_data= validation_generator, validation_steps= validation_generator.n // 32, callbacks=[checkpointer , earlystopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5148d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train_loss','val_loss'], loc = 'upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b357cd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"retina_weights.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210f760c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the performance of the model\n",
    "evaluate = model.evaluate(test_generator, steps = test_generator.n // 32, verbose =1)\n",
    "\n",
    "print('Accuracy Test : {}'.format(evaluate[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9111b1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning label names to the corresponding indexes\n",
    "labels = {0: 'Mild', 1: 'Moderate', 2: 'No_DR', 3:'Proliferate_DR', 4: 'Severe'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d987a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading images and their predictions \n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "import cv2\n",
    "\n",
    "prediction = []\n",
    "original = []\n",
    "image = []\n",
    "count = 0\n",
    "\n",
    "for item in range(len(test)):\n",
    "  # code to open the image\n",
    "  img= PIL.Image.open(test['Image'].tolist()[item])\n",
    "  # resizing the image to (256,256)\n",
    "  img = img.resize((256,256))\n",
    "  # appending image to the image list\n",
    "  image.append(img)\n",
    "  # converting image to array\n",
    "  img = np.asarray(img, dtype= np.float32)\n",
    "  # normalizing the image\n",
    "  img = img / 255\n",
    "  # reshaping the image in to a 4D array\n",
    "  img = img.reshape(-1,256,256,3)\n",
    "  # making prediction of the model\n",
    "  predict = model.predict(img)\n",
    "  # getting the index corresponding to the highest value in the prediction\n",
    "  predict = np.argmax(predict)\n",
    "  # appending the predicted class to the list\n",
    "  prediction.append(labels[predict])\n",
    "  # appending original class to the list\n",
    "  original.append(test['Labels'].tolist()[item])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d75187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the test accuracy \n",
    "score = accuracy_score(original,prediction)\n",
    "print(\"Test Accuracy : {}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25fbda0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the results\n",
    "import random\n",
    "fig=plt.figure(figsize = (100,100))\n",
    "for i in range(20):\n",
    "    j = random.randint(0,len(image))\n",
    "    fig.add_subplot(20, 1, i+1)\n",
    "    plt.xlabel(\"Prediction: \" + prediction[j] +\"   Original: \" + original[j])\n",
    "    plt.imshow(image[j])\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1057b9c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
